# 4.1 그라파나 관측 가능성

### p189

> 오픈서치, 코텍스(Cortex)를 포함한 많은 관측 가능성 오픈소스 가운데 그라파는 제약이 적고 다양한 표준을 지원한다.

<details>
<summary>OpenSearch란?</summary>

### 1. **Opensearch란?**

- **Opensearch**는 Elasticsearch와 Kibana를 기반으로 만들어진 **검색 및 데이터 시각화 플랫폼**입니다.
- 데이터를 효율적으로 저장하고 검색할 수 있으며, 이를 활용해 대시보드와 리포트를 생성할 수 있습니다.
- 로그 데이터, 이벤트 데이터, 메트릭 등 다양한 유형의 데이터를 처리하는 데 사용됩니다.

---

### 2. **왜 Opensearch를 사용할까?**

- **빅데이터 처리**: 많은 데이터를 빠르게 검색하고 분석 가능.
- **로그 및 모니터링**: 서버, 애플리케이션 로그를 수집하고 문제를 진단.
- **데이터 시각화**: 대시보드에서 데이터를 그래프와 차트로 쉽게 분석.
- **오픈 소스**: 상업용 라이선스 없이 무료로 사용 가능.

---

### 3. **Opensearch의 주요 구성 요소**

Opensearch는 두 가지 주요 컴포넌트로 구성됩니다.

### ① **Opensearch (Core Engine)**

- 데이터를 저장하고 검색하는 데 사용되는 **검색 엔진** 역할을 합니다.
- JSON 문서 형식으로 데이터를 저장하며, 이를 기반으로 고속 검색과 필터링을 수행합니다.
- 예를 들어, "지난 24시간 동안 에러 로그만 보여줘"와 같은 요청을 빠르게 처리할 수 있습니다.

### ② **Opensearch Dashboards**

- 데이터를 **시각화하고 관리**할 수 있는 웹 기반 도구입니다.
- 차트, 그래프, 지도 등을 사용하여 데이터를 분석.
- 사용자 정의 대시보드를 만들어 실시간 모니터링 가능.
    - 예: 서버 상태, 애플리케이션 성능, 사용자 활동 등.

---

### 4. **Opensearch의 작동 원리**

### 데이터 흐름:

1. **데이터 입력**
    - 로그 파일, 메트릭 데이터, 이벤트 데이터를 Opensearch로 전송.
    - 데이터를 수집하는 도구로 Logstash, Fluentd, Beats 등이 사용됨.
2. **데이터 저장**
    - JSON 형식으로 데이터를 저장하고 인덱싱하여 검색이 빠르게 이루어지도록 준비.
3. **데이터 검색 및 분석**
    - 사용자가 요청(Query)을 통해 원하는 데이터를 검색.
    - Opensearch Dashboards에서 데이터를 시각화하여 분석.

---

### 5. **Opensearch의 주요 기능**

- **Full-text Search**: 텍스트 데이터를 효율적으로 검색.
- **인덱싱 및 필터링**: 데이터를 분류하고 빠르게 검색 가능.
- **로그 분석**: 실시간으로 로그 데이터를 수집하고 문제를 진단.
- **확장성**: 대규모 데이터 처리가 가능하며, 클러스터 구성으로 성능을 확장.

---

### 6. **Opensearch의 사용 사례**

- **로그 및 이벤트 관리**
    - 서버와 애플리케이션에서 생성된 로그를 수집하고 분석하여 장애를 빠르게 해결.
- **보안 분석**
    - 네트워크 활동과 보안 이벤트를 모니터링하여 위협 탐지.
- **애플리케이션 모니터링**
    - 실시간 사용자 활동, 성능 데이터를 모니터링.
- **빅데이터 검색**
    - 전자 상거래, 뉴스 웹사이트 등에서 대규모 데이터 검색.

---

### 7. **Opensearch 설치 방법**

- **Docker**로 간단히 설치:

```shell
docker pull opensearchproject/opensearch:latest
docker pull opensearchproject/opensearch-dashboards:latest
```

- **Kubernetes**: Helm Chart를 사용하여 클러스터로 배포 가능.
- **로컬 설치**: 다운로드 후 실행 가능한 형태로 제공.

---

### 8. **Opensearch와 Elasticsearch의 차이점**

- Opensearch는 **Elasticsearch 7.10.2** 버전을 기반으로 Amazon이 주도하여 개발.
- **오픈 소스 철학**을 중시하며, 상업용 라이선스 없이 사용 가능.
- 최신 Elasticsearch에는 없는 기능을 추가하거나, 커뮤니티 피드백을 반영해 발전 중.

</details>

<details>
<summary>Cortex란?</summary>

### 1. **Cortex란?**

- Cortex는 Prometheus 데이터를 **장기적으로 안전하게 저장하고** 대규모로 관리할 수 있는 도구입니다.
- 특히 **클라우드 환경에서 로그와 메트릭을 처리**하는 데 유용합니다.

---

### 2. **Cortex의 역할**

Cortex는 다음과 같은 문제를 해결합니다:

- Prometheus는 데이터를 로컬에 저장하기 때문에 **스케일링**과 **장기 데이터 보존**이 어렵습니다.
- Cortex는 Prometheus 데이터를 **분산 스토리지**에 저장하여 대규모 데이터를 처리하고, 여러 클라이언트가 데이터를 공유할 수 있도록 만듭니다.

---

### 3. **Cortex의 작동 방식**

### 데이터를 어떻게 처리하나요?

1. **데이터 수집**
    - Prometheus 또는 다른 데이터 수집 도구가 Cortex로 데이터를 보냅니다.
2. **데이터 저장**
    - 데이터를 분산된 클라우드 스토리지(예: AWS S3, Google Cloud Storage)에 저장합니다.
    - 압축과 인덱싱을 통해 데이터를 효율적으로 저장합니다.
3. **데이터 쿼리**
    - 사용자는 Cortex를 통해 PromQL(Prometheus Query Language)을 사용하여 데이터를 검색하고 분석합니다.

---

### 4. **Cortex의 주요 기능**

- **수평 확장(Scalability)**
대규모 데이터를 여러 서버에 분산하여 처리합니다.
- **장기 스토리지 지원(Long-term Storage)**
Prometheus 데이터를 클라우드 스토리지에 저장하여 오랫동안 보존합니다.
- **다중 테넌시(Multi-tenancy)**
여러 사용자가 같은 인프라를 공유하면서도 데이터를 안전하게 격리할 수 있습니다.
- **고가용성(High Availability)**
시스템 장애에도 데이터를 안정적으로 유지합니다.

---

### 5. **Cortex의 주요 구성 요소**

Cortex는 다양한 서비스로 구성되어 있으며, 각 서비스가 특정 역할을 합니다.

- **Ingester**: 데이터를 받아들이고 임시로 저장합니다.
- **Distributor**: 데이터를 여러 Ingester로 분배합니다.
- **Querier**: 사용자가 요청한 쿼리를 실행하고 결과를 반환합니다.
- **Storage**: 데이터를 클라우드 스토리지(S3, GCS 등)에 저장합니다.
- **Frontend**: 쿼리 요청을 관리하고 최적화합니다.

---

### 6. **Cortex 설치 방법**

Cortex를 실행하려면 Kubernetes나 Docker를 사용하는 것이 일반적입니다.

### Docker Compose 예시:

```yaml
version: "3"
services:
  cortex:
    image: quay.io/cortexproject/cortex:latest
    ports:
      - "9009:9009"
    command: -config.file=/etc/cortex/config.yml
    volumes:
      - ./config.yml:/etc/cortex/config.yml
```

### Kubernetes 설치:

Helm Chart를 사용하여 설치할 수 있습니다:

</details>

<details>
<summary>Thanos vs Cortex vs Mimir</summary>

**Thanos**, **Cortex**, 그리고 **Mimir**는 모두 Prometheus 데이터를 **확장성**, **고가용성**, **장기 저장** 등을 위해 설계된 오픈 소스 프로젝트입니다.

## 1. **공통점**

- **Prometheus 확장**: 모두 Prometheus와 호환되며 기존 Prometheus의 한계를 극복하기 위해 만들어졌습니다.
- **장기 저장**: 데이터를 로컬 대신 클라우드 스토리지(S3, GCS 등)에 저장합니다.
- **고가용성**: 장애에도 데이터 손실 없이 안정적인 모니터링을 제공합니다.
- **수평 확장**: 대규모 환경에서도 데이터를 분산 처리할 수 있습니다.
- **PromQL 지원**: Prometheus의 쿼리 언어(PromQL)를 그대로 사용할 수 있습니다.

---

## 2. **개별 소개**

### **Thanos**

- **특징**: Prometheus의 확장성을 제공하면서도 비교적 간단한 아키텍처를 유지.
- **구성 요소**:
    - **Sidecar**: Prometheus와 연결하여 데이터를 클라우드 스토리지로 보냄.
    - **Store Gateway**: 클라우드 스토리지에서 데이터를 가져옴.
    - **Querier**: 여러 Prometheus 인스턴스를 통합하여 쿼리 가능.
    - **Compactor**: 저장된 데이터를 압축하고 관리.
- **장점**:
    - Prometheus의 로컬 저장소를 그대로 활용 가능.
    - 간단한 설정으로 클러스터링 및 장기 스토리지 지원.
- **단점**:
    - Cortex나 Mimir에 비해 다중 테넌시(Multi-tenancy)가 기본적으로 강력하지 않음.
    - 대규모 시스템에서는 성능 최적화가 필요할 수 있음.

---

### **Cortex**

- **특징**: Prometheus 데이터를 클라우드에서 장기 저장 및 다중 테넌시 지원.
- **구성 요소**:
    - **Distributor**: 데이터를 여러 노드에 분산.
    - **Ingester**: 데이터를 임시 저장하고, 클라우드 스토리지에 저장.
    - **Querier**: 데이터를 검색하고 분석.
    - **Storage**: 클라우드 스토리지에 데이터를 저장.
- **장점**:
    - **다중 테넌시 지원**: 여러 팀이나 고객 데이터를 격리하여 관리.
    - 확장성과 성능에 초점.
    - 데이터 압축과 TTL(수명) 설정 지원.
- **단점**:
    - 구성과 운영이 Thanos보다 복잡.
    - Kubernetes와의 통합이 필수적인 경우가 많음.

---

### **Mimir**

- **특징**: Cortex를 기반으로 한 확장된 솔루션으로, 추가적인 최적화와 기능을 제공.
- **개발 주체**: Grafana Labs에서 주도.
- **추가 기능**:
    - **Querier 병렬화 최적화**: 대규모 쿼리를 빠르게 처리.
    - **알람 관리**: 알림 관련 기능을 강화.
    - **보다 간단한 설정**: Cortex 대비 설정이 간소화됨.
- **장점**:
    - Cortex의 모든 장점을 포함하며 사용성을 개선.
    - Grafana와의 통합이 최적화.
    - 대규모 클러스터 환경에서도 높은 성능.
- **단점**:
    - Cortex보다 새롭고 커뮤니티 지원이 상대적으로 적음.
    - 오픈 소스이지만 Grafana Labs 의존도가 있음.

---

## 3. **비교표**

| **특징** | **Thanos** | **Cortex** | **Mimir** |
| --- | --- | --- | --- |
| **개발 주체** | CNCF | CNCF | Grafana Labs |
| **장기 저장** | 클라우드 스토리지 | 클라우드 스토리지 | 클라우드 스토리지 |
| **다중 테넌시** | 기본 제공하지 않음 | 완벽 지원 | 완벽 지원 |
| **구성 복잡도** | 비교적 간단 | 복잡 | Cortex보다 단순화됨 |
| **알람 관리** | Prometheus의 알람 기능 사용 | 별도 관리 필요 | 개선된 알람 관리 기능 제공 |
| **대규모 확장성** | 제한적 | 뛰어남 | 뛰어남 |
| **최적화** | 기본 제공 | 일부 수동 최적화 필요 | 자동 최적화 및 병렬 처리 지원 |
| **통합** | Prometheus 중심 | Prometheus, Kubernetes와 통합 가능 | Grafana와 최적화된 통합 |

---

## 4. **어떤 것을 선택할까?**

- **Thanos**:
    - 단순한 설정과 운영이 필요한 경우.
    - Prometheus를 그대로 활용하면서 장기 저장 및 기본 확장만 필요할 때.
    - 다중 테넌시가 필요하지 않다면 추천.
- **Cortex**:
    - 대규모 환경에서 **고성능**과 **다중 테넌시**가 필요할 때.
    - Kubernetes와 밀접한 통합이 필요한 경우.
    - Prometheus 데이터를 중앙에서 관리하려는 팀 환경에 적합.
- **Mimir**:
    - **최신 기능**과 **성능 최적화**를 원할 때.
    - Cortex보다 간단한 설정을 선호하고 Grafana 통합이 중요한 경우.
    - 대규모 엔터프라이즈 환경에서 안정성과 효율성을 모두 추구할 때.

---

## 5. **비유로 이해하기**

- **Thanos**: "혼자서 큰 집을 관리하는 집사."
    - 기본적인 모니터링과 데이터를 보존하는 데 충분.
- **Cortex**: "호텔 관리 시스템."
    - 여러 사람(테넌트)이 사용하는 데이터를 체계적으로 관리.
- **Mimir**: "고급 호텔 관리 시스템."
    - Cortex의 기능을 기반으로, 추가적인 편리함과 성능을 제공.

---

## 6. 결론

- **초심자**: Thanos
- **대규모 팀 환경**: Cortex
- **최신 기술과 높은 성능**: Mimir


</details>


[Opensearch](https://github.com/opensearch-project/OpenSearch), [Cortex](https://github.com/cortexproject/cortex)   
[참고링크1](https://gurumee92.tistory.com/236), [참고링크2](https://velog.io/@yieon/Comparison-of-open-source-solutions-for-scaling-high-availability-Prometheus-based-monitoring)

### p190

> 이 책에서 의미하는 그라파나 관측 가능성은 위의 네 가지 소프트웨어(Grafana LGTM 스택)를 지칭하는 것이라 할 수 있다.
> - Loki: 로그 관리
> - Grafana: 대시보드
> - Tempo: 추적 관리
> - Mimir: 메트릭 관리  
> <img width="414" alt="스크린샷 2024-12-02 오후 4 53 34" src="https://github.com/user-attachments/assets/258cb788-2c7e-4cfc-9807-4106276ee645">  

<details>
<summary>RUM이란?</summary>

### 1. **RUM이란?**

- **Real User Monitoring**의 약자로, 말 그대로 **실제 사용자**가 웹사이트나 애플리케이션에서 하는 행동을 실시간으로 추적하고 분석하는 방법입니다.
- 사용자가 어떤 페이지를 방문하고, 얼마나 오래 머물렀는지, 페이지 로딩 속도가 얼마나 걸렸는지를 측정합니다.
- 사용자의 **경험 품질**(User Experience)을 개선하기 위한 도구입니다.

---

### 2. **RUM이 필요한 이유**

1. **실제 사용자 관점에서 성능 확인**
    
    서버 성능만 확인하는 것이 아니라, **사용자가 실제로 느끼는 로딩 속도와 반응 속도**를 측정합니다.
    
2. **문제 발견 및 해결**
    
    페이지 로딩 속도가 느리거나 특정 기능이 작동하지 않는 문제가 발생하면 이를 즉시 감지할 수 있습니다.
    
3. **사용자 경험 향상**
    
    데이터를 바탕으로 사용자 경험을 개선하면 이탈률을 줄이고 만족도를 높일 수 있습니다.
    

---

### 3. **RUM의 작동 방식**

RUM은 웹사이트나 애플리케이션에 **작은 JavaScript 코드**를 삽입하여 데이터를 수집합니다.

이 데이터를 분석하여 사용자 경험을 측정합니다.

### 주요 데이터:

1. **페이지 로딩 속도**: 페이지가 열릴 때까지 걸린 시간.
2. **사용자 경로**: 사용자가 어떤 순서로 페이지를 탐색했는지.
3. **클릭 이벤트**: 사용자가 클릭한 버튼이나 링크.
4. **오류 보고**: 사용 중 발생한 자바스크립트 오류 등.
5. **지역 및 기기 정보**: 사용자의 위치, 브라우저, OS 등.

---

### 4. **RUM의 주요 지표**

- **First Contentful Paint (FCP)**: 첫 번째로 사용자에게 표시된 콘텐츠의 로딩 시간.
- **Largest Contentful Paint (LCP)**: 가장 큰 콘텐츠가 로딩되는 시간.
- **Time to Interactive (TTI)**: 페이지가 완전히 반응 가능한 상태가 되기까지 걸린 시간.
- **Error Rate**: 사용자 경험 중 발생한 오류 비율.
- **Session Duration**: 사용자가 웹사이트에서 머문 시간.

---

### 5. **RUM의 사용 사례**

- **웹사이트 성능 최적화**: 느린 페이지를 찾아 로딩 속도를 개선.
- **사용자 경험 분석**: 사용자 행동 데이터를 기반으로 UI/UX 개선.
- **문제 해결**: 특정 지역이나 브라우저에서 발생하는 문제를 빠르게 파악.

---

### 6. **RUM과 APM의 차이점**

- **RUM**: 실제 사용자의 데이터를 수집하여 경험을 분석.
- **APM (Application Performance Monitoring)**: 서버와 애플리케이션 내부의 성능 데이터를 모니터링.

### 비유로 설명:

- RUM은 "사용자가 식당에서 음식을 먹고 나서 남긴 리뷰"를 모으는 것.
- APM은 "주방에서 음식이 어떻게 만들어지는지"를 모니터링하는 것.

---

### 7. **RUM 도구 추천**

다음은 RUM 기능을 제공하는 주요 도구입니다:

- **Google Analytics**: 간단한 웹사이트 분석.
- **New Relic Browser**: 세부적인 사용자 경험 모니터링.
- **Datadog RUM**: RUM과 APM을 통합하여 관찰 가능성 강화.
- **Grafana Faro**: Grafana의 오픈소스 RUM 도구.

</details>

[참고링크1](https://blog.naver.com/watch_all/223052003531)

### p191

> 관측 가능성을 설치하고 구성하기에 앞서, 우선적으로 준비해야 하는 사항을 살펴보자.   
> <img width="351" alt="스크린샷 2024-12-02 오후 5 23 56" src="https://github.com/user-attachments/assets/0cc73c63-1840-4c78-8f52-d5905cc6a02d">   
> 먼저 인프라를 구성하고 캐시, 객체 스토리지, 서비스 디스커버리 등 공통적으로 사용하는 애플리케이션을 구성한다. 최종적으로 그라파나 관측 가능성을 구성한다.

### p192

> 그라파나 관측 가능성은 헬름으로만 설치할 수 있고, 이스티오와 예거 등은 오퍼레이터도 제공하므로 구성 요구 사항에 따라 결정하면 된다.

<details>
<summary>Grafana LGTM 스택은 헬름으로만 설치 가능한가?</summary>
다른 방법으로도 설치 가능하다. Docker Compose를 이용하여 설치할 수도 있지만 Helm Chart를 사용하여 설치하는 것이 가장 간편하다.

<details>
<summary>Docker Compose 파일 예시</summary>

```yaml
version: "3.7"
services:
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - loki
      - tempo
      - mimir

  loki:
    image: grafana/loki:latest
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml

  promtail:
    image: grafana/promtail:latest
    volumes:
      - /var/log:/var/log
    command: -config.file=/etc/promtail/config.yaml

  tempo:
    image: grafana/tempo:latest
    ports:
      - "3200:3200"

  mimir:
    image: grafana/mimir:latest
    ports:
      - "8080:8080"
```

</details>

</details>

### p193

> 지금까지 주요한 시스템과 인프라를 설치하고 구성했다. 이제부터는 관측 가능성의 기반이 되는 애플리케이션을 설치한다. 관측 가능성은 네트워크, 저장장치 등과 다양한 상호작용을 필요로 하면, 모든 작업은 쿠버네티스에서 이루어진다. 구성되는 오픈소스는 미니오, 레디스, 콘술이다.

<details>
<summary>Minio ← 오픈소스 객체 스토리지</summary>

- **정의**: Minio는 오픈 소스 객체 스토리지 서버입니다. 쉽게 말해, 클라우드 기반의 파일 저장소를 구축할 수 있는 소프트웨어입니다.
- **주요 기능**:
    - **S3 호환성**: Amazon S3와 호환되기 때문에, S3 API를 사용하는 애플리케이션에서 쉽게 사용할 수 있습니다.
    - **분산 스토리지**: 여러 서버에 데이터를 분산 저장하여 데이터의 내구성과 가용성을 높일 수 있습니다.
    - **간단한 설치**: 가벼운 설치와 설정으로 로컬 개발환경 또는 클라우드에서 빠르게 사용할 수 있습니다.
- **사용 사례**:
    - 애플리케이션의 이미지, 동영상, 백업 파일 등을 저장할 때.
    - 클라우드 스토리지를 자체 구축하거나, 작은 규모의 프로젝트에 S3 호환 스토리지가 필요할 때.

</details>

<details>
<summary>Redis ← 오픈소스 캐시</summary>

- **정의**: Redis는 메모리 기반의 데이터 구조 서버입니다. 매우 빠른 데이터 읽기/쓰기 속도를 제공하는 인메모리 데이터베이스입니다.
- **주요 기능**:
    - **키-값 저장소**: 데이터를 키와 값의 쌍으로 저장하고 빠르게 조회할 수 있습니다.
    - **다양한 데이터 구조**: 문자열, 해시, 리스트, 세트, 정렬된 세트 등 다양한 데이터 구조를 지원합니다.
    - **높은 성능**: 데이터를 메모리에 저장하므로 디스크 기반 데이터베이스보다 훨씬 빠른 속도를 자랑합니다.
    - **캐싱**: 자주 사용하는 데이터를 캐시하여 성능을 높일 때 많이 사용됩니다.
- **사용 사례**:
    - 웹 애플리케이션의 세션 저장소로 사용.
    - 캐싱을 통해 데이터베이스의 부하를 줄이고 성능을 향상시킬 때.
    - 실시간 채팅, 카운터, 순위 시스템 등 빠른 속도가 필요한 애플리케이션.

</details>

<details>
<summary>Consul ← 오픈소스 서비스 레지스트리</summary>

- **정의**: Consul은 서비스 메쉬 및 서비스 발견을 위한 오픈 소스 도구입니다. 쉽게 말해, 분산 시스템에서 서비스들이 서로를 찾고 연결할 수 있도록 돕는 소프트웨어입니다.
- **주요 기능**:
    - **서비스 발견**: 네트워크 내에서 서비스들을 쉽게 찾고 연결할 수 있도록 지원합니다.
    - **분산 키-값 저장소**: 설정 정보나 상태 데이터를 저장하고 관리할 수 있습니다.
    - **헬스 체크**: 서비스의 상태를 모니터링하고, 문제가 있는 서비스는 자동으로 제외합니다.
    - **서비스 메시**: 마이크로서비스 간의 통신을 안전하고 효율적으로 관리합니다.
- **사용 사례**:
    - 마이크로서비스 환경에서 서비스 간의 네트워크 주소를 동적으로 관리할 때.
    - 클라우드 네이티브 애플리케이션의 설정 및 상태 관리를 위해.
    - 서비스 간의 트래픽을 안전하게 라우팅하고 제어할 때.

</details>

### p194

> Memcached vs Redis

### p194

> 캐시 적중률을 구하는 경우에도 자바 오프 힙 off-heap을 사용할 수 있지만, 레디스를 사용하면 캐시 적중률을 쉽게 구할 수 있으므로 여러모로 유용하다. 메모리에 직접적으로 접근하는 것보다 레디스를 사용하면 디버깅이 쉽다.

### p195

> 분산 시스템의 구성 정보를 관리하기 위한 툴: 주키퍼 vs 콘술

### p200

> 쿠버네티스 중심으로 구축되는 클라우드 네이티브 환경은 상태가 없는(stateless) 환경이고, 변경이 자주 발생하는 동적인 환경이다.

### p200

> CMDB: Configuration Management Database

### p201

> 그라파나에서 제공하는 헬름 차트는 콘술 대신 멤버리스트, 미니오 대신 AWS S3, 레디스 대신 멤캐시드를 사용한다.

# 4.2 로키 로그 관리

### p202

일래스틱의 유료화 → 그라파나 로키로 로그 시스템 재구축 사례 발생

### p202

> 로키의 주요 컴포넌트   
> <img width="610" alt="스크린샷 2024-12-02 오후 2 16 11" src="https://github.com/user-attachments/assets/e0609823-2078-4ec8-8952-587e22fceafd">  
> - 로키의 컴포넌트는 크게 읽기, 쓰기, 저장 컴포넌트로 구분된다.
> - 레플리케이션 팩터와 리밸런싱 기능 제공

### p218

> 로키는 해시 링과 가십 프로토콜을 사용해서 내부적으로 샤드를 관리한다. 이를 위해 멤버리스트를 기본으로 사용하는데, 먼저 다음과 같이 멤버리스트를 구성한다.

### p219

> 로키, 템포는 레디스, Memcached를 지원하고, 미미르는 Memcached만 지원한다.

### p221

> 프롬테일 외에도 플루언트비트 등 다른 로그 수집기도 호환성을 제공한다.

### p221

> 기존에는 일래스틱서치 외에 우수한 로그 관리 솔루션이 부재하였다. 일래스틱서치는 우수한 로그 관리 솔루션이지만, 로키는 쿠버네티스 오토스케일링과 객체 스토리지를 지원함으로써 확장성 측면에서 문제가 없으며, 향후에도 오픈소스 라이선스를 지원할 예정이다.

### p221

> 로그를 생성하는 에이전트: Flog
